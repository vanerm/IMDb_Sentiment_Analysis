# üé¨ IMDb Sentiment Analysis

An√°lisis de sentimiento de rese√±as de pel√≠culas del dataset **IMDb**, utilizando t√©cnicas de **Procesamiento de Lenguaje Natural (NLP)**, **Machine Learning** y **Deep Learning**, con un enfoque comparativo sobre distintas representaciones del texto.

---

## üìå Descripci√≥n del proyecto

Este proyecto tiene como objetivo desarrollar y evaluar distintos modelos de **clasificaci√≥n binaria de sentimiento** (positivo / negativo) aplicados a rese√±as de pel√≠culas del dataset IMDb.

Se analizan y comparan enfoques basados en:
- Representaciones cl√°sicas del texto (Bag of Words, TF-IDF)
- Embeddings distribuidos a nivel documento
- Modelos de Machine Learning tradicionales
- Modelos de Deep Learning implementados con **Keras**

El foco principal del trabajo es **comparar el impacto de la representaci√≥n del texto y la complejidad del modelo sobre el desempe√±o final**, priorizando un an√°lisis riguroso y controlado.

---

## üéØ Objetivo general

Desarrollar y evaluar modelos de Machine Learning y Deep Learning capaces de predecir el sentimiento (positivo o negativo) de rese√±as de pel√≠culas del dataset IMDb, utilizando t√©cnicas de procesamiento de texto.

---

## üéØ Objetivos espec√≠ficos

- Analizar exploratoriamente el dataset de rese√±as de IMDb.
- Aplicar t√©cnicas de preprocesamiento de texto mediante NLP.
- Comparar distintos m√©todos de vectorizaci√≥n del texto.
- Entrenar modelos cl√°sicos de Machine Learning para clasificaci√≥n de sentimiento.
- Implementar modelos de Deep Learning con Keras (ANN / MLP) utilizando embeddings.
- Evaluar y comparar el desempe√±o de los distintos enfoques.

---

## üß™ Enfoque metodol√≥gico

El proyecto sigue un pipeline t√≠pico de **Ciencia de Datos aplicada a texto**, que incluye:

1. **An√°lisis exploratorio de los datos** (EDA)
   - Distribuci√≥n de clases
   - Longitud de rese√±as (caracteres y palabras)
   - Nubes de palabras
   - An√°lisis de tokens m√°s frecuentes

2. **Preprocesamiento ling√º√≠stico del texto**
   - Limpieza y normalizaci√≥n
   - Tokenizaci√≥n
   - Eliminaci√≥n de stopwords
   - Lematizaci√≥n con spaCy
   - Manejo de negaciones y expresiones emocionales

3. **Vectorizaci√≥n del contenido textual**
   - Bag of Words (BoW) con n-gramas
   - TF-IDF (Term Frequency-Inverse Document Frequency)
   - Word2Vec embeddings (entrenados sobre el corpus)
   - Representaciones a nivel documento (promedio de embeddings)

4. **Entrenamiento de modelos de Machine Learning**
   - Regresi√≥n Log√≠stica
   - Random Forest
   - MLPClassifier

5. **Implementaci√≥n de modelos de Deep Learning**
   - Red Neuronal Artificial (ANN) con Keras/TensorFlow
   - Entrenamiento sobre embeddings de documentos

6. **Evaluaci√≥n y an√°lisis comparativo de resultados**
   - M√©tricas de clasificaci√≥n (Accuracy, Precision, Recall, F1-score)
   - Comparaci√≥n entre distintos enfoques
   - An√°lisis de curvas de entrenamiento

El an√°lisis avanza desde m√©todos basados en conteo hasta embeddings entrenados y redes neuronales, evaluando el equilibrio entre complejidad del modelo y ganancia real en performance.

---

## ü§ñ Modelos implementados

### üîπ Machine Learning
- **Regresi√≥n Log√≠stica** sobre TF-IDF y Bag of Words
- **Random Forest** sobre TF-IDF
- **MLPClassifier** (scikit-learn) sobre embeddings de documentos
- Comparaci√≥n de n-gramas (unigrams, bigrams)

### üîπ Deep Learning (Keras)
- Red Neuronal Artificial Multicapa (ANN)
- Arquitectura deliberadamente simple:
  - Una √∫nica capa densa oculta
  - Regularizaci√≥n mediante Dropout
  - Funci√≥n de activaci√≥n ReLU
  - Capa de salida sigmoide para clasificaci√≥n binaria

---

## üß† Justificaci√≥n del dise√±o de la ANN

La arquitectura utilizada corresponde a una **red neuronal artificial multicapa (ANN) con una √∫nica capa densa oculta**.

Esta elecci√≥n responde a un dise√±o deliberadamente simple, con el objetivo de:
- Evaluar el aporte del enfoque de Deep Learning sobre embeddings.
- Evitar introducir complejidad innecesaria en la arquitectura.
- Facilitar la comparaci√≥n directa con modelos m√°s simples.

No se utilizaron arquitecturas m√°s profundas debido a que:
- El tama√±o y la naturaleza del dataset no justifican redes profundas.
- No se observaron mejoras sustanciales frente a modelos m√°s simples.
- Arquitecturas m√°s complejas incrementan el riesgo de sobreajuste y el costo computacional.

---

## üìä M√©tricas de evaluaci√≥n

Los modelos fueron evaluados utilizando:
- Accuracy
- Precision
- Recall
- F1-score
- An√°lisis de curvas de entrenamiento (loss y accuracy)
- Comparaci√≥n entre m√©tricas de entrenamiento y validaci√≥n

---

## üìÅ Estructura del repositorio

```
IMDb_Sentiment_Analysis/
‚îÇ
‚îú‚îÄ‚îÄ IMDb_Sentiment_Analysis_VanesaMizrahi.ipynb  # Notebook principal con el an√°lisis completo
‚îú‚îÄ‚îÄ imdb_sentiment_analysis_vanesamizrahi.py      # Script Python exportado del notebook
‚îú‚îÄ‚îÄ README.md                                      # Este archivo
‚îî‚îÄ‚îÄ .gitignore                                     # Archivos ignorados por Git
```


---

## üõ†Ô∏è Tecnolog√≠as utilizadas

### Lenguaje y Librer√≠as Principales
- **Python 3.x**
- **pandas** - Manipulaci√≥n y an√°lisis de datos
- **numpy** - C√°lculos num√©ricos
- **scikit-learn** - Machine Learning (Regresi√≥n Log√≠stica, Random Forest, MLPClassifier)
- **TensorFlow / Keras** - Deep Learning
- **gensim** - Word2Vec para embeddings
- **spaCy** - Procesamiento avanzado de lenguaje natural (lematizaci√≥n, tokenizaci√≥n)

### Visualizaci√≥n y Utilidades
- **matplotlib** - Visualizaci√≥n de datos
- **seaborn** - Visualizaci√≥n estad√≠stica
- **wordcloud** - Nubes de palabras
- **tqdm** - Barras de progreso

### Otras herramientas
- **kagglehub** - Descarga del dataset desde Kaggle
- **Jupyter Notebook** / **Google Colab** - Entorno de desarrollo

---

## üì¶ Dataset

El proyecto utiliza el **IMDb Dataset de 50K Movie Reviews** disponible en Kaggle:

- **Fuente**: [Kaggle ‚Äì IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/data)
- **Tama√±o**: 50,000 rese√±as (25,000 positivas y 25,000 negativas)
- **Formato**: CSV con columnas `review` y `sentiment`
- **Descarga**: El c√≥digo incluye la descarga autom√°tica mediante `kagglehub`

---

## üöÄ Instalaci√≥n y Uso

### Requisitos previos

- Python 3.7 o superior
- Acceso a Kaggle (para descargar el dataset)

### Instalaci√≥n de dependencias

```bash
pip install pandas numpy scikit-learn tensorflow gensim spacy matplotlib seaborn wordcloud tqdm kagglehub
```

### Descarga del modelo de spaCy

Para el preprocesamiento de texto, se requiere el modelo de ingl√©s de spaCy:

```bash
python -m spacy download en_core_web_sm
```

### Ejecuci√≥n

El proyecto est√° disponible en dos formatos:

1. **Notebook Jupyter**: `IMDb_Sentiment_Analysis_VanesaMizrahi.ipynb`
   - Abrir en Jupyter Notebook o Google Colab
   - Ejecutar las celdas en orden

2. **Script Python**: `imdb_sentiment_analysis_vanesamizrahi.py`
   - Ejecutar directamente: `python imdb_sentiment_analysis_vanesamizrahi.py`

### Nota sobre Google Colab

El proyecto incluye c√≥digo espec√≠fico para Google Colab. Si ejecutas localmente, puedes comentar o adaptar las secciones relacionadas con `google.colab`.

---

## üìä Resultados destacados

Los modelos fueron evaluados utilizando m√∫ltiples m√©tricas (Accuracy, Precision, Recall, F1-score). Los principales hallazgos incluyen:

- **Regresi√≥n Log√≠stica + TF-IDF/Bag of Words**: Desempe√±o s√≥lido con F1-score cercano a 0.90
- **Modelos basados en embeddings**: Representaciones m√°s compactas y sem√°nticamente ricas
- **Deep Learning (Keras)**: Flexibilidad adicional con mejoras moderadas en m√©tricas globales

---

## üìå Conclusiones generales

Los resultados muestran que, para este dataset en particular, los modelos cl√°sicos bien ajustados sobre representaciones simples del texto alcanzan desempe√±os competitivos frente a enfoques de Deep Learning.

La implementaci√≥n de Deep Learning con Keras aporta mayor flexibilidad y control sobre el proceso de entrenamiento, aunque las mejoras en m√©tricas globales resultan moderadas. Esto refuerza la importancia de evaluar cuidadosamente el trade-off entre complejidad del modelo y ganancia real en performance.

---

## üìÑ Licencia
El proyecto est√° disponible bajo la licencia MIT, permitiendo su uso libre para fines personales, acad√©micos o experimentales.
Para m√°s detalles, consulta el archivo LICENSE.

---

## ‚úã About Me

Soy **Vanesa Mizrahi**, desarrolladora de software iOS y **Data Scientist en formaci√≥n**, con foco en el an√°lisis y modelado de datos aplicados a problemas reales.

Durante la Diplomatura en Data Science profundic√© en el uso de **Python, SQL, Machine Learning y t√©cnicas de Deep Learning**, abordando proyectos que integran an√°lisis exploratorio, procesamiento de datos, modelado predictivo y evaluaci√≥n comparativa de enfoques.

Mis principales √°reas de inter√©s incluyen:
- An√°lisis exploratorio de datos y visualizaci√≥n
- Procesamiento de Lenguaje Natural (NLP)
- Modelos de Machine Learning supervisados
- Introducci√≥n a Deep Learning aplicado a datos reales
- Desarrollo de soluciones anal√≠ticas con criterio metodol√≥gico y enfoque pr√°ctico

---

## üéì Prop√≥sito Educativo

Este repositorio forma parte del trabajo desarrollado en el marco del curso **Data Science III: NLP & Deep Learning aplicado a Ciencia de Datos**, donde se aplican t√©cnicas de NLP, modelos cl√°sicos y redes neuronales para el an√°lisis de sentimiento sobre texto, el cual forma parte de mi especializaci√≥n a trav√©s de la Diplomatura en Data Science [CoderHouse](https://www.coderhouse.com/ar/diplomaturas/data/?pipe_source=google&pipe_medium=cpc&pipe_campaign=1&gad_source=1&gad_campaignid=13952864596&gbraid=0AAAAACoxfTL7S4LjLGDCtBrigIZUvaOtI&gclid=CjwKCAiAxc_JBhA2EiwAFVs7XJlquLs6YOrHV_5FBSUgw11RG-8BGH6YVHXJN2QfehgVqOBGVghiqxoCOQsQAvD_BwE).



- üåê **GitHub**: [@vanerm](https://github.com/vanerm)  
- üíº **LinkedIn**: [vanesamizrahi](https://www.linkedin.com/in/vanesamizrahi)  
- üìì **Notebook en Google Colab**: [Ver notebook](https://colab.research.google.com/drive/1G_0RDVRkqttwNkXLlOUIeJdVHQyq25_w?usp=sharing)

---

## üôè Agradecimientos

- **Kaggle** por proporcionar el dataset de rese√±as de IMDb
- Comunidad de c√≥digo abierto por las librer√≠as utilizadas (scikit-learn, TensorFlow, gensim, spaCy, entre otras)

---

## üìù Notas adicionales

- El c√≥digo est√° optimizado para ejecutarse en **Google Colab**, pero puede adaptarse f√°cilmente para ejecuci√≥n local
- Se recomienda tener al menos 8GB de RAM para procesar el dataset completo
- El entrenamiento de modelos puede tomar varios minutos dependiendo del hardware disponible
- Para una experiencia interactiva completa, se recomienda usar el notebook en lugar del script Python

---

